
Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-credential-initializer-dvdng[0m
{"level":"warn","ts":1587285022.9361856,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: \"ref: refs/heads/0.8.0-**-support-backwards-incompats\" is not a valid GitHub commit ID"}
{"level":"info","ts":1587285022.9368193,"logger":"fallback-logger","caller":"creds-init/main.go:40","msg":"Credentials initialized."}

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-working-dir-initializer-hl44z[0m
{"level":"warn","ts":1587285023.9632206,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1587285023.9643836,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /workspace/source\"; output "}

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-place-tools[0m

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-git-source-cb-kubecd-environment-bootv3-de-t7ch6-q29mp[0m
{"level":"warn","ts":1587285032.1000903,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: \"ref: refs/heads/0.8.0-**-support-backwards-incompats\" is not a valid GitHub commit ID"}
{"level":"info","ts":1587285033.2283025,"logger":"fallback-logger","caller":"git/git.go:103","msg":"Successfully cloned https://github.com/cb-kubecd/environment-bootv3-dev.git @ v0.0.6 in path /workspace/source"}

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-git-merge[0m
Using SHAs from PULL_REFS=master:ab93530f0f22cfdc22de1d6d45c321280ba7e3c4
WARNING: no SHAs to merge, falling back to initial cloned commit

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-verify-secrets[0m
created directory /secrets/**-boot
loaded Secrets from: local in namespace ** with Secret **-boot-secrets
exported Secrets to file: /secrets/**-boot/secrets.yaml

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-validate-git[0m
Git configured for user: jenkins-x-bot and email jenkins-x@googlegroups.com

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-verify-preinstall[0m
no need to reconnect to cluster
Cloning the Jenkins X versions repo https://github.com/jenkins-x/**r-versions.git with ref refs/heads/master to /builder/home/.**/jenkins-x-versions
Locking version stream https://github.com/jenkins-x/**r-versions.git to release v0.0.2. Jenkins X will use this release rather than master to resolve all versions from now on.
writing the following to the OWNERS file for the development environment repository:
approvers:
- jstrachan
- rawlingsj
- daveconde
reviewers:
- jstrachan
- rawlingsj
- daveconde
WARNING: TLS is not enabled so your webhooks will be called using HTTP. This means your webhook secret will be sent to your cluster in the clear. See https://jenkins-x.io/docs/getting-started/setup/boot/#ingress for more information
Verifying the kubernetes cluster before we try to boot Jenkins X in namespace: **
Trying to lazily create any missing resources to get the current cluster ready to boot Jenkins X
Verifying Ingress...
Clearing the domain 35.240.127.185.nip.io as when using auto-DNS domains we need to regenerate to ensure its always accurate in case the cluster or ingress service is recreated

Using namespace '**' from context named '' on server ''.

Verifying Storage...
WARNING: Your requirements have not enabled cloud storage for logs - we recommend enabling this for kubernetes provider gke
WARNING: Your requirements have not enabled cloud storage for reports - we recommend enabling this for kubernetes provider gke
WARNING: Your requirements have not enabled cloud storage for repository - we recommend enabling this for kubernetes provider gke
WARNING: Your requirements have not enabled cloud storage for backup - we recommend enabling this for kubernetes provider gke
Storage configuration looks good

Validating Kaniko secret in namespace **

verified there is a ConfigMap config in namespace **
verified there is a ConfigMap plugins in namespace **
Cluster looks good, you are ready to '** boot' now!


Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-install-jx-crds[0m
Jenkins X CRDs upgraded with success

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-generate-helmfile[0m

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-helmfile-system[0m
Adding repo stable https://kubernetes-charts.storage.googleapis.com
"stable" has been added to your repositories

Updating repo
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "stable" chart repository
Update Complete. âŽˆ Happy Helming!âŽˆ 

Affected releases are:
  nginx-ingress (stable/nginx-ingress) UPDATED

Upgrading release=nginx-ingress, chart=stable/nginx-ingress
Release "nginx-ingress" has been upgraded. Happy Helming!
NAME: nginx-ingress
LAST DEPLOYED: Sun Apr 19 08:30:55 2020
NAMESPACE: nginx
STATUS: deployed
REVISION: 25
TEST SUITE: None
NOTES:
The nginx-ingress controller has been installed.
It may take a few minutes for the LoadBalancer IP to be available.
You can watch the status by running 'kubectl --namespace nginx get services -o wide -w nginx-ingress-controller'

An example Ingress that makes use of the controller:

  apiVersion: extensions/v1beta1
  kind: Ingress
  metadata:
    annotations:
      kubernetes.io/ingress.class: nginx
    name: example
    namespace: foo
  spec:
    rules:
      - host: www.example.com
        http:
          paths:
            - backend:
                serviceName: exampleService
                servicePort: 80
              path: /
    # This section is only required if TLS is to be enabled for the Ingress
    tls:
        - hosts:
            - www.example.com
          secretName: example-tls

If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided:

  apiVersion: v1
  kind: Secret
  metadata:
    name: example-tls
    namespace: foo
  data:
    tls.crt: <base64 encoded cert>
    tls.key: <base64 encoded key>
  type: kubernetes.io/tls

Listing releases matching ^nginx-ingress$
nginx-ingress	nginx    	25      	2020-04-19 08:30:55.340812125 +0000 UTC	deployed	nginx-ingress-1.34.2	0.30.0     


UPDATED RELEASES:
NAME            CHART                  VERSION
nginx-ingress   stable/nginx-ingress    1.34.2


Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-verify-ingress[0m
Waiting to find the external host name of the ingress controller Service in namespace nginx with name nginx-ingress-controller
No domain flag provided so using default 35.240.127.185.nip.io to generate Ingress rules
defaulting the domain to 35.240.127.185.nip.io and modified /workspace/source/**-requirements.yml

Showing logs for build [32mcb-kubecd-environment-bootv3-de-t7ch6-6[0m stage [32mrelease[0m and container [32mstep-helmfile-apps[0m
Adding repo jenkins-x https://storage.googleapis.com/chartmuseum.jenkins-x.io
"jenkins-x" has been added to your repositories

Updating repo
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "stable" chart repository
...Successfully got an update from the "jenkins-x" chart repository
Update Complete. âŽˆ Happy Helming!âŽˆ 

Building dependency release=repositories, chart=../repositories
Affected releases are:
  chartmuseum (jenkins-x/chartmuseum) UPDATED
  **boot-helmfile-resources (jenkins-x/**boot-helmfile-resources) UPDATED
  **ui (jenkins-x/**ui) UPDATED
  lighthouse (jenkins-x/lighthouse) UPDATED
  nexus (jenkins-x/nexus) UPDATED
  repositories (../repositories) UPDATED
  tekton (jenkins-x/tekton) UPDATED

Upgrading release=nexus, chart=jenkins-x/nexus
Upgrading release=**boot-helmfile-resources, chart=jenkins-x/**boot-helmfile-resources
Upgrading release=lighthouse, chart=jenkins-x/lighthouse
Upgrading release=tekton, chart=jenkins-x/tekton
Upgrading release=chartmuseum, chart=jenkins-x/chartmuseum
Upgrading release=**ui, chart=jenkins-x/**ui
Upgrading release=repositories, chart=../repositories
Release "chartmuseum" has been upgraded. Happy Helming!
NAME: chartmuseum
LAST DEPLOYED: Sun Apr 19 08:31:11 2020
NAMESPACE: **
STATUS: deployed
REVISION: 24
TEST SUITE: None
NOTES:
** Please be patient while the chart is being deployed **

Get the ChartMuseum URL by running:

  export POD_NAME=$(kubectl get pods --namespace ** -l "app=chartmuseum" -l "release=chartmuseum" -o jsonpath="{.items[0].metadata.name}")
  echo http://127.0.0.1:8080/
  kubectl port-forward $POD_NAME 8080:8080 --namespace **

Listing releases matching ^chartmuseum$
chartmuseum	**       	24      	2020-04-19 08:31:11.854404133 +0000 UTC	deployed	chartmuseum-1.1.7	0.7.1      

Listing releases matching ^nexus$
Release "nexus" has been upgraded. Happy Helming!
NAME: nexus
LAST DEPLOYED: Sun Apr 19 08:31:12 2020
NAMESPACE: **
STATUS: deployed
REVISION: 24
TEST SUITE: None
NOTES:
It may take a few minutes for Nexus to become ready

nexus	**       	24      	2020-04-19 08:31:12.183519587 +0000 UTC	deployed	nexus-0.1.21	           

Release "tekton" has been upgraded. Happy Helming!
NAME: tekton
LAST DEPLOYED: Sun Apr 19 08:31:12 2020
NAMESPACE: **
STATUS: deployed
REVISION: 24
TEST SUITE: None
NOTES:
Tekton Pipelines

Listing releases matching ^tekton$
Release "**ui" has been upgraded. Happy Helming!
NAME: **ui
LAST DEPLOYED: Sun Apr 19 08:31:13 2020
NAMESPACE: **
STATUS: deployed
REVISION: 24
TEST SUITE: None
NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace ** -l "app=**ui,release=**ui" -o jsonpath="{.items[0].metadata.name}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl port-forward $POD_NAME 8080:80

Listing releases matching ^**ui$
Release "lighthouse" has been upgraded. Happy Helming!
NAME: lighthouse
LAST DEPLOYED: Sun Apr 19 08:31:13 2020
NAMESPACE: **
STATUS: deployed
REVISION: 24
TEST SUITE: None
NOTES:
Get the application URL by running these commands:

kubectl get ingress lighthouse-lighthouse

Listing releases matching ^lighthouse$
**ui	**       	24      	2020-04-19 08:31:13.168837238 +0000 UTC	deployed	**ui-0.0.1217	0.0.1217   

tekton	**       	24      	2020-04-19 08:31:12.806608297 +0000 UTC	deployed	tekton-0.0.51	           

lighthouse	**       	24      	2020-04-19 08:31:13.345144033 +0000 UTC	deployed	lighthouse-0.0.493	0.0.493    

Release "**boot-helmfile-resources" has been upgraded. Happy Helming!
NAME: **boot-helmfile-resources
LAST DEPLOYED: Sun Apr 19 08:31:13 2020
NAMESPACE: **
STATUS: deployed
REVISION: 24
TEST SUITE: None

Listing releases matching ^**boot-helmfile-resources$
**boot-helmfile-resources	**       	24      	2020-04-19 08:31:13.351126208 +0000 UTC	deployed	**boot-helmfile-resources-0.0.132	           


UPDATED RELEASES:
NAME                        CHART                                  VERSION
chartmuseum                 jenkins-x/chartmuseum                    1.1.7
nexus                       jenkins-x/nexus                         0.1.21
tekton                      jenkins-x/tekton                        0.0.51
**ui                        jenkins-x/**ui                        0.0.1217
lighthouse                  jenkins-x/lighthouse                   0.0.493
**boot-helmfile-resources   jenkins-x/**boot-helmfile-resources    0.0.132


FAILED RELEASES:
NAME
repositories
in ./helmfile.yaml: failed processing release repositories: helm exited with status 1:
  Error: UPGRADE FAILED: rendered manifests contain a new resource that already exists. Unable to continue with update: existing resource conflict: kind: SourceRepository, namespace: **, name: jstrachan-nodey442
[31m
Pipeline failed on stage 'release' : container 'step-helmfile-apps'. The execution of the pipeline has stopped.[0m
